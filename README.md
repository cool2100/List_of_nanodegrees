# List of Nanodegree


Certificate | MOOC | Date Completed | Status |
------------ | ------------- | -------------------- | -------------------- |
**[1_product_management](#1_product_management)**  | Udacity | Apr 2020 | :heavy_check_mark:
**[2_Artificial_Intelligence_Product_Management](#2_Artificial_Intelligence_Product_Management)**  | Udacity | Jan 2020 | :heavy_check_mark:
**[3_Growth_Product_Manager](#3_Growth_Product_Manager)**  | Udacity | Dec 2020 | :heavy_check_mark:
**[4_Data_Product_Manager](#4_Data_Product_Manager)**  | Udacity | Apr 2021 | :heavy_check_mark:
**[5_Data_Engineering](#5_Data_Engineering)**  | Udacity | Dec 2020 | :heavy_check_mark:
**[6_Data_Streaming](#6_Data_Streaming)**  | Udacity | Dec 2020 | :heavy_check_mark:
**[7_AWS_Cloud_Architect](#7_AWS_Cloud_Architect)**  | Udacity | Dec 2020 | :heavy_check_mark:
**[8_Full_Stack_Product_Management](#8_Full_Stack_Product_Management)**  | Product School | Jan 2020 | :heavy_check_mark:


# [1_product_management](#1_product_management)

### [1_product_management] 
Module | Description | Deliverables |
------------ | ------------- | -------------------- |
M1_Product Strategy | - Create a compelling vision and strategy that will set up the team to solve those problems. - Understand how to communicate effectively to get people excited and invested in your ideas. | ProductPitchTemplate.ppt
M2_Product Design | Take an idea through concept, design, and user validation phases, and create a spec to handoff to Engineering for development. Use design-thinking methodologies to explore various ideas, and then converge on a single idea. Map out the full concept through creation of a prototype that can be used to validate that you’re solving a problem for real users | - ProductRequirementDocument_V1-SetStage <br> - DesignSprintResearchPlan <br> - ProductRequirementDocument_V2-Handoff
M3_Product Development | Collaborate with cross-functional teams and stakeholders to guide them through planning and execution. Manage stakeholder expectations and handle risks that arise, reprioritizing feature and sprint priorities to tackle competing requests. | - Co-ordinationActivitiesMap <br> SprintPlanningMeet <br> Re-prioritizeSprintBacklog
M4_Product Launch | Create a launch plan, identify the launch risks, and figure out how to minimize their impact on your launch. Collaborate with a variety of teams including Marketing, Sales, Customer Support, and more to prepare them to interface with customers as the product is launched. Execute the launch and use feedback from your customers to determine the next steps for your product. | ProductRequirementDocument <br> MarketingGuide <br> Sales_and_CustomerSupport_Guide <br> UserGuide <br> LaunchEmail_Template

# [2_Artificial_Intelligence_Product_Management](#2_Artificial_Intelligence_Product_Management)

### [2_Artificial_Intelligence_Product_Management] 

NanoDegree Course Details: https://www.udacity.com/course/ai-product-manager-nanodegree--nd088

Project Name | Detailed Description | Complete
------------ | ------------- | -------------------- | 
Create a Medical Image Annotation Data Set with Appen | - In this project, you will create an annotated training data set on Appen’s platform. You’ll build a classification system that can help flag serious cases of pneumonia. | :heavy_check_mark:
Build a Model with Google AutoML | - Build models using automated machine learning, from data to results with no coding required. You’ll implement your model with four different variants of data to evaluate how the data affects performance. | :heavy_check_mark:
Capstone Project | - Develop a business proposal for an AI product for a use case of your choosing. You’ll develop the business case, define success metrics, scope the dataset and build a post-deployment monitoring plan. | :heavy_check_mark:

# [3_Growth_Product_Manager](#3_Growth_Product_Manager)

### [3_Growth_Product_Manager] 

NanoDegree Course Details: https://www.udacity.com/course/monetization-strategy--nd037-3

**Project:** In this project you will build a monetization model for a post-revenue B2B SaaS business, and then modify it for a different pricing scheme.
You will be provided with a description of the company, its product, pricing scheme, and a dataset of recent months' activity. 
Based on this model, you will then come up with product improvements that can improve monetization KPIs as well as suggest a change to the pricing scheme. Finally you will modify the original models to accommodate a given modified pricing scheme.

1. Build a monetization model for a post-revenue B2B SaaS business, and then come up with hypotheses about potential changes to the monetization strategy. 
2. Build monetization models based on the company, its product, pricing scheme, and a dataset of recent customer transactions.
3. Identify and create hypotheses about changing the pricing metric and pricing plans to optimize the business’ monetization strategy.
4. Experimentation plan to test these hypotheses.

Monetization Business Models | 
1. Acquisition
2. Unit Economics
3. Customer Accounting
4. Revenue Accounting
5. Growth Ratios

# [5_Data_Engineering](#5_Data_Engineering)

## [5_Data_Engineering]

NanoDegree Course Details: https://www.udacity.com/course/data-engineer-nanodegree--nd027

Project Folder | Project | Detailed Description | Complete
------------ | ------------- | -------------------- | ---------
**[Project 1 - PostgreSQL](1_Project_Data_Modeling_with_Postgres)**  |  Model user activity data stored in json and csv files for a music streaming app called Sparkify by creating a Relational database | <br> - Created a relational database using PostgreSQL  <br> - Developed a Star Schema (Fact and Dimension tables) data model. <br> - Developed an ETL pipeline to optimize queries in order to understand what songs users listen to. | :heavy_check_mark:
**[Project 2 - Cassandra](2_Project_Data_Modeling_with_Apache_Cassandra)**  | Model user activity data stored in json and csv files for a music streaming app called Sparkify by creating a NoSQL db using Cassandra  | Created a nosql database using Apache Cassandra <br> Developed denormalized tables optimized writes of transactional data on user sessions | :heavy_check_mark:
**[Project 3 - Data Warehouse w AWS Redshift](3_Project_Cloud_Data%20Warehouse)** | Build a data warehouse in AWS Redshift | Creating a Redshift Cluster, IAM Roles, Security groups <br> Develop an ETL Pipeline that copies data from S3 buckets into staging tables to be processed into a star schema <br> Developed a star schema so that Sparkify analytics team can continue finding insights | :heavy_check_mark:
**[Project 4 - Data Lake w Apache Spark](4_Project_Data%20Lake_Spark)**| Build a ETL pipeline data lake with Apache Spark | Create an EMR Hadoop Cluster <br> Develop the ETL Pipeline a) copy datasets from S3, process data using Spark and write to S3 using efficient partitioning and parquet formatting | :heavy_check_mark:
**[Project 5 - Airflow Pipelines](5_Project_Data_Pipelines_w_Apache_Airflow)**| Automate the Sparkify data infrastructure using Apache Airflow | Developed custom operators to perform tasks such as staging data, filling the data warehouse, and validating through data quality checks| :heavy_check_mark:
**[Project 6 - Capstone Project]()**| Modernize the data infrastructure (Kaggle dataset) | Developed a ETL pipeline to load dataset from S3 bucket, process using Spark and store them back in S3 in parquet format for analytics | :heavy_check_mark:

# [6_Data_Streaming](#6_Data_Streaming)

## [6_Data_Streaming]

NanoDegree Course Details: https://www.udacity.com/course/data-streaming-nanodegree--nd029

**Project:** Optimizing Public Transport
- To construct an event pipeline around Kafka that allows to simulate and display the status of train lines in real time. A simple static website (dashboard) is built to monitor the trains move from station to station
Static Website - Real Time dashboard

*Architecture*
1. _Kafka Producers_: Emit events
2. _Kafka REST proxy producer_: Weather data is sent to Kafka
3. _Kafka Connect_: Postgres SQL into Kafka
4. _Faust Stream processor_: Ingest data from Kafka Connect and transform the data
5. _KSQL_: Aggregate the turnstile events

6. _Kafka Consumer_: Consume the data in web server that is going to serve the transit status pages to our commuters

## [7_AWS_Cloud_Architect](#7_AWS_Cloud_Architect)

NanoDegree Course Details: https://www.udacity.com/course/aws-cloud-architect-nanodegree--nd063

## [7_AWS_Cloud_Architect]

Project Folder | Project | Detailed Description | Complete
------------ | ------------- | -------------------- | ---------
**[Project 1 - Design_for_Availability_Reliability_Resilience](1_Project_Design_for_Availability_Reliability_Resilience)**  |  Monitor, react and Recover | <br> - Build a Multi-Availability Zone, Multi-Region database and show how to use it in multiple geographically separate AWS regions. <br> Build a website hosting solution that is versioned so that any data destruction and accidents can be quickly and easily undone. | :heavy_check_mark:
**[Project 2 - Design_for_Provision_Monitor_AWS_Infrastructure_Scale](2_Project_Design_for_Provision_Monitor_AWS_Infrastructure_Scale)**  | Use AWS tools to identify and implement best practices for cost, and identify and understand the elements required to design and architect scalable infrastructure. <br> - Provision and destroy infrastructure from the command line using the AWS CLI and Terraform | <br> - Plan, design, provision, and monitor infrastructure in AWS using Terraform and other open source tools. <br> Optimize infrastructure for cost and performance. | :heavy_check_mark:
**[Project 3 - Design_for_Security](3_Project_Design_for_Security)**  | Cloud Security - Secure access to cloud services, infrastructure, data. <br> - Best practices and strategies around securing access to cloud services and infrastructure.  | <br> - Deploy and assess a simple web application environment’s security posture. <br> - Test the security of the environment by simulating attack scenarios and exploiting cloud configuration vulnerabilities. <br> - Implement monitoring to identify insecure configurations and malicious activity. <br> Harden and secure the environment. <br> Design a DevSecOps pipeline | :heavy_check_mark:


